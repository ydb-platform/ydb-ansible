storage_config_generation: 0
static_erasure: mirror-3-dc
host_configs: # the list of available host configurations in the cluster.
- drive:
  - path: /dev/disk/by-partlabel/ydb_disk_1
    type: SSD
  - path: /dev/disk/by-partlabel/ydb_disk_2
    type: SSD
  - path: /dev/disk/by-partlabel/ydb_disk_3
    type: SSD
  host_config_id: 1

hosts:
- host: ycydb-s1
  node_id: 1
  host_config_id: 1
  walle_location:
    body: 1
    data_center: 'zone-a'
    rack: '1'
- host: ycydb-s2
  node_id: 2
  host_config_id: 1
  walle_location:
    body: 2
    data_center: 'zone-b'
    rack: '2'
- host: ycydb-s3
  node_id: 3
  host_config_id: 1
  walle_location:
    body: 3
    data_center: 'zone-c'
    rack: '3'

domains_config:
  # There can be only one root domain in a cluster. Domain name prefixes all scheme objects names, e.g. full name of a table table1 in database db1.
  # in a cluster with domains_config.domain.name parameter set to Root would be equal to /Root/db1/table1
  domain:
  - name: Domain0
    domain_id: 1
    storage_pool_types:
    - kind: ssd
      pool_config:
        box_id: 1
        # fault tolerance mode name - none, block-4-2, or mirror-3-dc..
        # See docs for more details https://ydb.tech/en/docs/deploy/configuration/config#domains-blob
        erasure_species: mirror-3-dc
        kind: ssd
        geometry:
          realm_level_begin: 10
          realm_level_end: 20
          domain_level_begin: 10
          domain_level_end: 256
        pdisk_filter:
        - property:
          - type: SSD  # device type to match host_configs.drive.type
        vdisk_kind: Default
  state_storage:
  - ring:
      node: [1, 2, 3]
      nto_select: 3
    ssid: 1
  security_config:
    enforce_user_token_requirement: true
    monitoring_allowed_sids:
    - "root"
    - "ADMINS"
    - "DATABASE-ADMINS"
    administration_allowed_sids:
    - "root"
    - "ADMINS"
    - "DATABASE-ADMINS"
    viewer_allowed_sids:
    - "root"
    - "ADMINS"
    - "DATABASE-ADMINS"
    register_dynamic_node_allowed_sids:
    - "root@builtin" # required, does not add any real extra permissions
    - "registerNode@cert"

client_certificate_authorization:
  request_client_certificate: true
  client_certificate_definitions:
    - member_groups: ["registerNode@cert"]
      subject_terms:
      - short_name: "O"
        values: ["YDB Self-Signed Authority"]

blob_storage_config:         # configuration of static blobstorage group.
                             # YDB uses this group to store system tablets' data, like SchemeShard
  service_set:
    groups:
    - erasure_species: mirror-3-dc # fault tolerance mode name for the static group
      rings:          # in mirror-3-dc must have exactly 3 rings or availability zones
      - fail_domains:  # first record: fail domains of the static group describe where each vdisk of the static group should be located.
        - vdisk_locations:
          - node_id: ycydb-s1
            pdisk_category: SSD
            path: /dev/disk/by-partlabel/ydb_disk_1
        - vdisk_locations:
          - node_id: ycydb-s1
            pdisk_category: SSD
            path: /dev/disk/by-partlabel/ydb_disk_2
        - vdisk_locations:
          - node_id: ycydb-s1
            pdisk_category: SSD
            path: /dev/disk/by-partlabel/ydb_disk_3
      - fail_domains: # second ring: fail domains of the static group describe where each vdisk of the static group should be located.
        - vdisk_locations:
          - node_id: ycydb-s2
            pdisk_category: SSD
            path: /dev/disk/by-partlabel/ydb_disk_1
        - vdisk_locations:
          - node_id: ycydb-s2
            pdisk_category: SSD
            path: /dev/disk/by-partlabel/ydb_disk_2
        - vdisk_locations:
          - node_id: ycydb-s2
            pdisk_category: SSD
            path: /dev/disk/by-partlabel/ydb_disk_3
      - fail_domains: # third ring: fail domains of the static group describe where each vdisk of the static group should be located.
        - vdisk_locations:
          - node_id: ycydb-s3
            pdisk_category: SSD
            path: /dev/disk/by-partlabel/ydb_disk_1
        - vdisk_locations:
          - node_id: ycydb-s3
            pdisk_category: SSD
            path: /dev/disk/by-partlabel/ydb_disk_2
        - vdisk_locations:
          - node_id: ycydb-s3
            pdisk_category: SSD
            path: /dev/disk/by-partlabel/ydb_disk_3
channel_profile_config:
  profile:
  - channel:
    - erasure_species: mirror-3-dc
      pdisk_category: 1   # 0=ROT, 1=SSD, 2=NVME
      storage_pool_kind: ssd
    - erasure_species: mirror-3-dc
      pdisk_category: 1
      storage_pool_kind: ssd
    - erasure_species: mirror-3-dc
      pdisk_category: 1
      storage_pool_kind: ssd
    profile_id: 0
interconnect_config:
  start_tcp: true
  encryption_mode: OPTIONAL
  path_to_certificate_file: "/opt/ydb/certs/node.crt"
  path_to_private_key_file: "/opt/ydb/certs/node.key"
  path_to_ca_file: "/opt/ydb/certs/ca.crt"
grpc_config:
    cert: "/opt/ydb/certs/node.crt"
    key: "/opt/ydb/certs/node.key"
    ca: "/opt/ydb/certs/ca.crt"
    services_enabled:
    - legacy
table_service_config:
  sql_version: 1
bootstrap_config:
  shared_cache_config: {memory_limit: '4294967296'}
audit_config:
  file_backend:
    format: JSON
    file_path: "ydb-audit.log"
# Actor system config is appended to the configuration file by Ansible task.
# Provided here in the commented form for reference
#actor_system_config:
#  use_auto_config: true
#  node_type: STORAGE # STORAGE or COMPUTE
#  cpu_count: 6
